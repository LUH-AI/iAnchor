{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to normalize some features of the adult dataset\n",
    "# Taken from the orignal anchor implementation\n",
    "\n",
    "def map_array_values(array, value_map):\n",
    "    ret = array.copy()\n",
    "    for src, target in value_map.items():\n",
    "        ret[ret == src] = target\n",
    "    return ret\n",
    "\n",
    "def cap_gains_fn(x):\n",
    "    x = x.astype(float)\n",
    "    d = np.digitize(x, [0, np.median(x[x > 0]), float('inf')],\n",
    "                    right=True).astype('|S128')\n",
    "    return map_array_values(d, {'0': 'None', '1': 'Low', '2': 'High'})\n",
    "\n",
    "education_map = {\n",
    "    '10th': 'Dropout', '11th': 'Dropout', '12th': 'Dropout', '1st-4th':\n",
    "    'Dropout', '5th-6th': 'Dropout', '7th-8th': 'Dropout', '9th':\n",
    "    'Dropout', 'Preschool': 'Dropout', 'HS-grad': 'High School grad',\n",
    "    'Some-college': 'High School grad', 'Masters': 'Masters',\n",
    "    'Prof-school': 'Prof-School', 'Assoc-acdm': 'Associates',\n",
    "    'Assoc-voc': 'Associates',\n",
    "}\n",
    "\n",
    "occupation_map = {\n",
    "    \"Adm-clerical\": \"Admin\", \"Armed-Forces\": \"Military\",\n",
    "    \"Craft-repair\": \"Blue-Collar\", \"Exec-managerial\": \"White-Collar\",\n",
    "    \"Farming-fishing\": \"Blue-Collar\", \"Handlers-cleaners\":\n",
    "    \"Blue-Collar\", \"Machine-op-inspct\": \"Blue-Collar\", \"Other-service\":\n",
    "    \"Service\", \"Priv-house-serv\": \"Service\", \"Prof-specialty\":\n",
    "    \"Professional\", \"Protective-serv\": \"Other\", \"Sales\":\n",
    "    \"Sales\", \"Tech-support\": \"Other\", \"Transport-moving\":\n",
    "    \"Blue-Collar\",\n",
    "}\n",
    "\n",
    "country_map = {\n",
    "    'Cambodia': 'SE-Asia', 'Canada': 'British-Commonwealth', 'China':\n",
    "    'China', 'Columbia': 'South-America', 'Cuba': 'Other',\n",
    "    'Dominican-Republic': 'Latin-America', 'Ecuador': 'South-America',\n",
    "    'El-Salvador': 'South-America', 'England': 'British-Commonwealth',\n",
    "    'France': 'Euro_1', 'Germany': 'Euro_1', 'Greece': 'Euro_2',\n",
    "    'Guatemala': 'Latin-America', 'Haiti': 'Latin-America',\n",
    "    'Holand-Netherlands': 'Euro_1', 'Honduras': 'Latin-America',\n",
    "    'Hong': 'China', 'Hungary': 'Euro_2', 'India':\n",
    "    'British-Commonwealth', 'Iran': 'Other', 'Ireland':\n",
    "    'British-Commonwealth', 'Italy': 'Euro_1', 'Jamaica':\n",
    "    'Latin-America', 'Japan': 'Other', 'Laos': 'SE-Asia', 'Mexico':\n",
    "    'Latin-America', 'Nicaragua': 'Latin-America',\n",
    "    'Outlying-US(Guam-USVI-etc)': 'Latin-America', 'Peru':\n",
    "    'South-America', 'Philippines': 'SE-Asia', 'Poland': 'Euro_2',\n",
    "    'Portugal': 'Euro_2', 'Puerto-Rico': 'Latin-America', 'Scotland':\n",
    "    'British-Commonwealth', 'South': 'Euro_2', 'Taiwan': 'China',\n",
    "    'Thailand': 'SE-Asia', 'Trinadad&Tobago': 'Latin-America',\n",
    "    'United-States': 'United-States', 'Vietnam': 'SE-Asia'\n",
    "}\n",
    "\n",
    "married_map = {\n",
    "    'Never-married': 'Never-Married', 'Married-AF-spouse': 'Married',\n",
    "    'Married-civ-spouse': 'Married', 'Married-spouse-absent':\n",
    "    'Separated', 'Separated': 'Separated', 'Divorced':\n",
    "    'Separated', 'Widowed': 'Widowed'\n",
    "}\n",
    "\n",
    "label_map = {'<=50K': 'Less than $50,000', '>50K': 'More than $50,000'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt('/home/kevin/iml-ws21-projects-risingnumpygods/datasets/adult/adult.data', delimiter=',', dtype='|S128')\n",
    "\n",
    "all_column_names = [\n",
    "    \"Age\", \"Workclass\", \"fnlwgt\", \"Education\",\n",
    "    \"Education-Num\", \"Marital Status\", \"Occupation\",\n",
    "    \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\",\n",
    "    \"Capital Loss\", \"Hours per week\", \"Country\", 'Income'\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    1, 3, 5, 6, 7, 8, 9, 10, 11, 13\n",
    "]\n",
    "\n",
    "used_columns = [\n",
    "    0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13\n",
    "]\n",
    "\n",
    "# names of the columns after dropping unused columns\n",
    "column_names_after_dropping = [\n",
    "    x for i, x in enumerate(all_column_names) if i in used_columns\n",
    "]\n",
    "\n",
    "# idx of the categorical_columns after dropping unused columns\n",
    "categorical_features_after_dropping = [\n",
    "    used_columns.index(x) for x in categorical_columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "\n",
    "# transformize some cols\n",
    "\n",
    "transformations = {\n",
    "            3: lambda x: map_array_values(x, education_map),\n",
    "            5: lambda x: map_array_values(x, married_map),\n",
    "            6: lambda x: map_array_values(x, occupation_map),\n",
    "            10: cap_gains_fn,\n",
    "            11: cap_gains_fn,\n",
    "            13: lambda x: map_array_values(x, country_map),\n",
    "            14: lambda x: map_array_values(x, label_map),\n",
    "}\n",
    "\n",
    "for feature, transformation in transformations.items():\n",
    "    data[:, feature] = transformation(data[:, feature])\n",
    "\n",
    "# encode categorical features\n",
    "for feature in categorical_columns:\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    data[:, feature] = le.fit_transform(data[:, feature])\n",
    "\n",
    "# encode label\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "data[:, -1] = le.fit_transform(data[:, -1])\n",
    "\n",
    "# drop unused columns and split into data and labels\n",
    "X = data[:, used_columns]\n",
    "y = data[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize data\n",
    "\n",
    "import lime.lime_tabular\n",
    "\n",
    "X = X.astype(float)\n",
    "disc = lime.lime_tabular.QuartileDiscretizer(X, categorical_features_after_dropping, column_names_after_dropping)\n",
    "X = disc.discretize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9293605317442127\n",
      "Test 0.8407779638935418\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "c = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "c.fit(X_train, y_train)\n",
    "print('Train', sklearn.metrics.accuracy_score(y_train, c.predict(X_train)))\n",
    "print('Test', sklearn.metrics.accuracy_score(y_test, c.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n",
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n",
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n",
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n",
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n",
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n",
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n",
      "INFO:root: Start Sampling\n",
      "INFO:root: Start Beam Search\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from Anchor.anchor import Anchor, Tasktype\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    \"batch_size\": [8, 16, 32, 64, 128, 256, 512],\n",
    "    \"delta\": [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7],\n",
    "    \"epsilon\": [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7],\n",
    "}\n",
    "\n",
    "agg_data = []\n",
    "for key, values in params.items():\n",
    "    for value in values:\n",
    "        explainer = Anchor(Tasktype.TABULAR)\n",
    "        task_paras = {\"dataset\": X_train, \"column_names\": column_names_after_dropping}\n",
    "        method_paras = {\"beam_size\": 4, \"desired_confidence\": 0.9}\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        anchor = explainer.explain_instance(\n",
    "            input=X_test[1].reshape(1, -1),\n",
    "            predict_fn=c.predict,\n",
    "            method=\"beam\",\n",
    "            epsilon = value if key == \"epsilon\" else 0.1,\n",
    "            delta = value if key == \"delta\" else 0.1,\n",
    "            batch_size = value if key == \"batch_size\" else 16,\n",
    "            task_specific=task_paras,\n",
    "            method_specific=method_paras,\n",
    "            num_coverage_samples=100,\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        agg_data.append([\n",
    "            key, value, \n",
    "            anchor.feature_mask, anchor.precision, \n",
    "            anchor.n_samples, anchor.positive_samples, \n",
    "            anchor.coverage, end_time - start_time\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header = [\n",
    "    'parameter', 'value', 'feature_mask', \n",
    "    'precision', 'n_samples', 'positive_samples', 'coverage', 'search_duration']\n",
    "\n",
    "\n",
    "with open('hyperparam.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(agg_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ee014a394539ea33a681f57bab852aba5460f711bf7a82fe5b61ba0c6bc8483"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('iML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
