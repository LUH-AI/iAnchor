{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Text Explanation\n\nAn example how to use iAnchor for text data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport os.path\nimport numpy as np\nimport sklearn\nimport sklearn.model_selection\nimport sklearn.linear_model\nimport sklearn.ensemble\nimport spacy\nimport sys\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom ianchor import Tasktype\nfrom ianchor.anchor import Anchor\n\n\n# dataset from http://www.cs.cornell.edu/people/pabo/movie-review-data/\n# Link: http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\ndef load_polarity(path=\"./datasets/rt-polaritydata/\"):\n    data = []\n    labels = []\n    f_names = [\"rt-polarity.neg\", \"rt-polarity.pos\"]\n    for (l, f) in enumerate(f_names):\n        for line in open(os.path.join(path, f), \"rb\"):\n            try:\n                line.decode(\"utf8\")\n            except Exception:\n                continue\n            data.append(line.strip())\n            labels.append(l)\n    return data, labels\n\n\nif __name__ == \"__main__\":\n\n    # Prepare data\n    data, labels = load_polarity()\n    train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(\n        data, labels, test_size=0.2, random_state=42\n    )\n    train, val, train_labels, val_labels = sklearn.model_selection.train_test_split(\n        train, train_labels, test_size=0.1, random_state=42\n    )\n    train_labels = np.array(train_labels)\n    test_labels = np.array(test_labels)\n    val_labels = np.array(val_labels)\n\n    vectorizer = CountVectorizer(min_df=1)\n    vectorizer.fit(train)\n    train_vectors = vectorizer.transform(train)\n    test_vectors = vectorizer.transform(test)\n    val_vectors = vectorizer.transform(val)\n\n    # Get model\n    c = sklearn.linear_model.LogisticRegression(random_state=1234)\n    c.fit(train_vectors, train_labels)\n\n    predictions = c.predict(val_vectors)\n\n    print(\"Validation accuracy:\", sklearn.metrics.accuracy_score(val_labels, predictions))\n\n    def predict_lr(texts):\n        return c.predict(vectorizer.transform(texts))\n\n    spacy.cli.download(\"en_core_web_sm\")  # Otherwise spacy can not load it\n    nlp = spacy.load(\"en_core_web_sm\")\n    text_to_be_explained = \"This is a good book.\"\n\n    preprocessed_text = [word.text for word in nlp(text_to_be_explained)]\n\n    # Get the explainer\n    explainer = explainer = Anchor(Tasktype.TEXT)\n\n    method_paras = {\"beam_size\": 1, \"desired_confidence\": 0.95}\n    anchor = explainer.explain_instance(\n        preprocessed_text,\n        predict_lr,\n        method=\"beam\",\n        method_specific=method_paras,\n        num_coverage_samples=1,\n    )\n\n    visu = explainer.visualize(anchor, preprocessed_text)\n    print(visu)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}