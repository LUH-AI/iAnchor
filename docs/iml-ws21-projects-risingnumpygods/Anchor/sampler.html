<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>iml-ws21-projects-risingnumpygods.Anchor.sampler API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>iml-ws21-projects-risingnumpygods.Anchor.sampler</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import logging
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Callable, Optional, Protocol, Tuple, Union
from transformers import DistilBertTokenizer, DistilBertForMaskedLM
import torch

import matplotlib.pyplot as plt
import numpy as np
import torch
from skimage.segmentation import quickshift

from .candidate import AnchorCandidate
import matplotlib.pyplot as plt
import spacy


def exp_normalize(x):
    b = x.max()
    y = np.exp(x - b)
    return y / y.sum()


class Tasktype(Enum):
    &#34;&#34;&#34;
    Type of data that is going to be explained by the
    anchor.
    &#34;&#34;&#34;

    TABULAR = auto()
    IMAGE = auto()
    TEXT = auto()


class Sampler:
    &#34;&#34;&#34;
    Abstract Sampler that is used as a factory for its
    subclasses. Use create(Tasktype) to initialise sub-
    classes for each task.
    &#34;&#34;&#34;

    subclasses = {}

    def __init_subclass__(cls, **kwargs):
        &#34;&#34;&#34;
        Registers every subclass in the subclass-dict.
        &#34;&#34;&#34;
        super().__init_subclass__(**kwargs)
        cls.subclasses[cls.type] = cls

    @classmethod
    def create(
        cls,
        type: Tasktype,
        input: any,
        predict_fn: Callable,
        task_specific: dict,
        **kwargs
    ):
        &#34;&#34;&#34;
        Creates subclass depending on typ.

        Args:
            typ: Tasktype
        Returns:
            Subclass that is used for the given Tasktype.
        &#34;&#34;&#34;
        if type not in cls.subclasses:
            raise ValueError(&#34;Bad message type {}&#34;.format(type))

        return cls.subclasses[type](
            input, predict_fn, **task_specific
        )  # every sampler needs input and predict function


class TabularSampler(Sampler):
    &#34;&#34;&#34;
    TabularSampler generates new tabular instances 
    given an AnchorCandidate by fixiating the 
    candidates features and sampling random values
    within the dataset.
    &#34;&#34;&#34;

    type: Tasktype = Tasktype.TABULAR

    def __init__(
        self,
        input: any,
        predict_fn: Callable[[any], np.array],
        dataset: any,
        column_names: list,
    ):
        &#34;&#34;&#34;
        Initialises TabularSampler with the given
        predict_fn, input, dataset and column names.

        Predict_fn will be used to predict all the 
        samples and the input.

        Args:
            input (any): Tabular row that is to be explained.
            predict_fn (Callable[[any], np.array]): Black box model predict function.
            dataset (any): Tabular dataset from which samples will be collected.
            column_names (list): Columns names of the dataset.
        &#34;&#34;&#34;

        if dataset is None:
            assert &#34;Dataset must be given for tabular explaination.&#34;
        if column_names is None:
            assert &#34;Column names must be given for tabular explaination.&#34;

        self.predict_fn = predict_fn
        self.input = input
        self.label = predict_fn(input)
        self.dataset = dataset
        self.features = column_names
        self.num_features = self.dataset.shape[1]

        assert (
            len(column_names) == self.num_features
        ), &#34;column_names length must match dataset column dimension.&#34;

    def sample(
        self,
        candidate: AnchorCandidate,
        num_samples: int,
        calculate_labels: bool = True,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generates num_samples samples by choosing random values
        out of self.dataset and setting the self.input features 
        that are withing the candidates feature mask.

        Args:
            candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
            num_samples (int): Number of samples that shall be generated.
            calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
            candiates precision will be updated. Defaults to True.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, None]. In case 
            calculate_labels is False return [None, coverage_mask, None].
        &#34;&#34;&#34;

        if self.dataset.shape[0] &gt; num_samples:
            assert &#34;Batch size must be smaller or equal to dataset rows.&#34;

        # pertubate
        sample_idxs = np.random.choice(
            self.dataset.shape[0], size=num_samples, replace=False
        )

        # fixiate feature mask
        samples = np.copy(self.dataset[sample_idxs])
        samples[:, candidate.feature_mask] = self.input[0, candidate.feature_mask]

        # calculate converage mask
        masks = (samples[:, :] != self.input).astype(int)

        if not calculate_labels:
            return None, masks, None

        # predict samples
        preds = self.predict_fn(samples)

        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)

        return candidate, masks, None  # TODO remove third return variable


class ImageSampler(Sampler):
    &#34;&#34;&#34;
    Image sampling with the help of superpixels.
    The original input image is permuated by switching off superpixel areas.

    More details can be found on the following website:
    https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/
    &#34;&#34;&#34;

    type: Tasktype = Tasktype.IMAGE

    def __init__(
        self, input: any, predict_fn: Callable[[any], np.array], dataset: any = None
    ):
        &#34;&#34;&#34;
        Initialises ImageSampler with the given
        predict_fn, input and image dataset.

        Predict_fn will be used to predict all the 
        samples and the input.

        When dataset equals None samples are generated
        by utilising mean superpixels.

        Args:
            input (any): Image that is to be explained.
            predict_fn (Callable[[any], np.array]): Black box model predict function.
            dataset (any): Image dataset from which samples will be collected
        &#34;&#34;&#34;

        assert input.shape[2] == 3
        assert len(input.shape) == 3

        self.label = predict_fn(input[np.newaxis, ...])

        input = input.clone().cpu().detach().numpy()
        # run segmentation on the image
        self.features = quickshift(
            input.astype(np.double), kernel_size=4, max_dist=200, ratio=0.2
        )

        # parameters from original implementation
        segment_features = np.unique(self.features)
        self._n_features = len(segment_features)

        # create superpixel image by replacing superpixels by its mean in the original image
        self.sp_image = np.copy(input)
        for spixel in segment_features:
            self.sp_image[self.features == spixel, :] = np.mean(
                self.sp_image[self.features == spixel, :], axis=0
            )

        self.image = input
        self.predict_fn = predict_fn
        self.dataset = dataset

    def sample(
        self,
        candidate: AnchorCandidate,
        num_samples: int,
        calculate_labels: bool = True,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generates num_samples samples by choosing random values
        out of self.dataset and setting the self.input features 
        that are withing the candidates feature mask.

        When dataset is None then samples are generated by 
        utilizing the mean superpixel else the image datset
        is sampled

        Args:
            candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
            num_samples (int): Number of samples that shall be generated.
            calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
            candiates precision will be updated. Defaults to True.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, segmentations]. In case 
            calculate_labels is False return [None, coverage_mask, None].
        &#34;&#34;&#34;
        data = np.random.randint(
            0, 2, size=(num_samples, self._n_features)
        )  # generate random feature mask for each sample
        data[:, candidate.feature_mask] = 1  # set present features to one

        if not calculate_labels:
            return None, data, None

        if self.dataset is not None:
            return self.sample_dataset(candidate, data, num_samples)
        else:
            return self.sample_mean_superpixel(candidate, data, num_samples)

    def sample_dataset(
        self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Samples num_samples samples by utilising the image dataset.

        Args:
            candidate (AnchorCandidate): AnchorCandiate that shall be evaluted
            data (np.ndarray): Features masks
            num_samples (int): Number of samples to be generated.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, segmentations]
        &#34;&#34;&#34;
        perturb_sample_idxs = np.random.choice(
            range(self.dataset.shape[0]), num_samples, replace=True
        )

        samples = np.stack(
            [
                self.__generate_image(mask, self.dataset[pidx])
                for mask, pidx in zip(data, perturb_sample_idxs)
            ],
            axis=0,
        )

        preds = self.predict_fn(samples)
        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)

        return candidate, data, self.features

    def sample_mean_superpixel(
        self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Sample function for image data.
        Generates random image samples from the distribution around the original image.

        Args:
            candidate (AnchorCandidate)
            num_samples (int)
        Returns:
            candidate (AnchorCandidate)
        &#34;&#34;&#34;
        samples = np.stack(
            [self.__generate_image(mask, self.sp_image) for mask in data], axis=0
        )

        preds = self.predict_fn(samples)

        # assert isinstance(
        #     preds, np.ndarray
        # ), &#34;Result of your predict function should be of type numpy.ndarray&#34;

        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)

        return candidate, data, self.features  # TODO remove third return variable

    def __generate_image(
        self, feature_mask: np.ndarray, perturb_image: np.ndarray
    ) -&gt; np.array:
        &#34;&#34;&#34;
        Generate sample image given some feature mask.
        The true image will get permutated dependent on the feature mask.
        Pixel which are outmasked by the mask are replaced by the corresponding superpixel pixel.

        Args:
            feature_mask: np.ndarray
        Returns:
            permutated image: np.array
        &#34;&#34;&#34;
        img = self.image.copy()
        zeros = np.where(feature_mask == 0)[0]
        mask = np.zeros(self.features.shape).astype(bool)
        for z in zeros:
            mask[self.features == z] = True
        img[mask] = perturb_image[mask]

        return img

    @property
    def num_features(self):
        return self._n_features


class TextSampler(Sampler):
    &#34;&#34;&#34;
    TextSampler generates new text instances 
    given an AnchorCandidate by fixiating the 
    candidates features and replacing masked 
    words with alternatives given from bert 
    model.
    &#34;&#34;&#34;

    type: Tasktype = Tasktype.TEXT

    def __init__(self, input: any, predict_fn: Callable[[any], np.array]):
        &#34;&#34;&#34;
        Initialises TextSampler with the given
        predict_fn, input, dataset and nlp_object

        Predict_fn will be used to predict all the 
        samples and the input.

        Args:
            input (list(str)): Sentences as list of tokens.
            predict_fn (Callable[[any], np.array]): Black box model predict function.
        &#34;&#34;&#34;
        self.label = predict_fn([&#34; &#34;.join(input)])
        self.input = input
        self.num_features = len(self.input)
        self.predict_fn = predict_fn

        self.tokenizer = DistilBertTokenizer.from_pretrained(&#34;distilbert-base-cased&#34;)
        self.bert = DistilBertForMaskedLM.from_pretrained(&#34;distilbert-base-cased&#34;)

        # contains top500k probability of each word in the input
        self.pr = {}

        # caches bert predictions
        self.prob_cache = {}

        # mask each word separetly and predict topk given its context
        for i in range(len(self.input)):
            masked_sentence = self.input.copy()
            masked_sentence[i] = self.tokenizer.mask_token

            sentence = &#34; &#34;.join(masked_sentence)

            w, p = self.prob(sentence)[0]
            self.pr[self.input[i]] = min(0.5, dict(zip(w, p)).get(self.input[i], 0.01))

    def prob(self, sentence: str):
        &#34;&#34;&#34;
        Given a senteces with masked tokens predicts
        the cbow (word alternatives, exp normalized 
        probabilites) for each word.

        Args:
            sentence (str): Sentences which maskes word alternatives
                            and probabilites shall be predicted.

        Returns:
            results (list(tuple(str, float)))
        &#34;&#34;&#34;
        if sentence in self.prob_cache:
            return self.prob_cache[sentence]

        result = self.pred_topk_cbow(sentence)
        normalized_result = [(a, exp_normalize(b)) for a, b in result]

        self.prob_cache[sentence] = normalized_result
        return normalized_result

    def pred_topk_cbow(self, sentence):
        &#34;&#34;&#34;
        Give a sentences with masked tokens predict 
        alternative words (and the corresponding probabilities)
        via bert.

        For each masked token returns the top500 predictions
        with their probabilities.

        Returns:
            predictions (list(tuple(str, float)))
        &#34;&#34;&#34;
        # encode text
        encoded_text = self.tokenizer.encode(sentence, add_special_tokens=True)
        input = torch.tensor([encoded_text])

        with torch.no_grad():
            output = self.bert(input)[0]

        # get idx for mask token
        mask_token_idx = (
            np.array(encoded_text) == self.tokenizer.mask_token_id
        ).nonzero()[0]

        # predict top 500 for each masked word
        preds_per_word = []
        for i in mask_token_idx:
            v, top_preds = torch.topk(output[0, i], 500)
            words = self.tokenizer.convert_ids_to_tokens(top_preds)
            preds_per_word.append((words, v.numpy()))

        return preds_per_word

    def sample(
        self,
        candidate: AnchorCandidate,
        num_samples: int,
        calculate_labels: bool = True,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generates num_samples samples by choosing if words 
        that are not within the candiates feature mask should
        be masked given their original probability (self.pr).

        Args:
            candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
            num_samples (int): Number of samples that shall be generated.
            calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
            candiates precision will be updated. Defaults to True.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, None]. In case 
            calculate_labels is False return [None, coverage_mask, None].
        &#34;&#34;&#34;
        feature_masks = np.zeros((num_samples, len(self.input)))
        for idx, word in enumerate(self.input):
            if idx in candidate.feature_mask:
                continue

            # decide if we should mask the word or not
            prob = self.pr[word]
            feature_masks[:, idx] = np.random.choice(
                [0, 1], num_samples, p=[1 - prob, prob]
            )

        # unmask words in candidate mask
        feature_masks[:, candidate.feature_mask] = 1

        if not calculate_labels:
            return None, feature_masks, None

        return self.__sample_pertubated_sentences(candidate, feature_masks, num_samples)

    def __generate_sentence(self, feature_mask: np.ndarray) -&gt; str:
        &#34;&#34;&#34;
        Generate new sentence by masking words according to the
        feature mask. For each masked word new words are samples.
        This is done word for word in an iterative manner to generate
        more coherent sentences.

        Args:
            feature_mask (np.ndarray): Features mask where != 1 denotes 
                                        that a word shall be masked

        Returns:
            str: Generated sentence
        &#34;&#34;&#34;
        # Generate new sentences by masking words according to the
        # feature mask. Then new words are samples. This is done
        # done word for word

        # mask words given the feature mask
        sentence_cp = np.array(self.input, dtype=&#34;|U80&#34;)
        sentence_cp[feature_mask != 1] = self.tokenizer.mask_token

        # sample new word for each word
        masked_word = np.where(feature_mask == 0)[0]
        for word_idx in masked_word:
            mod_sentence = &#34; &#34;.join(sentence_cp)
            words, probs = self.prob(mod_sentence)[0]
            sentence_cp[word_idx] = np.random.choice(words, p=probs)

        feature_mask = sentence_cp == np.array(self.input, dtype=&#34;|U80&#34;)

        return &#34; &#34;.join(sentence_cp)

    def __sample_pertubated_sentences(
        self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generate num_sampels new sentences (via self.__generate_sentence),
        predicts the labels and updates the precision for the AnchorCandidate
        candidate.

        Args:
            candidate (AnchorCandidate): Candidate for which the samples will be generated for. 
                                            This candiates precisision will be updated in the process.
            data (np.ndarray): Several feature_masks. For each mask a new sentence will be generated.
            num_samples (int): Number of samples. Used to calculate the precision.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure [AnchorCandidate, feature_masks, None]
        &#34;&#34;&#34;
        sentences = np.apply_along_axis(self.__generate_sentence, 1, data).reshape(
            -1, 1
        )

        # predict pertubed sentences
        preds = self.predict_fn(sentences.flatten().tolist())
        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)
        return candidate, data, None</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.exp_normalize"><code class="name flex">
<span>def <span class="ident">exp_normalize</span></span>(<span>x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exp_normalize(x):
    b = x.max()
    y = np.exp(x - b)
    return y / y.sum()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler"><code class="flex name class">
<span>class <span class="ident">ImageSampler</span></span>
<span>(</span><span>input: <built-in function any>, predict_fn: Callable[[<built-in function any>], <built-in function array>], dataset: <built-in function any> = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Image sampling with the help of superpixels.
The original input image is permuated by switching off superpixel areas.</p>
<p>More details can be found on the following website:
<a href="https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/">https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/</a></p>
<p>Initialises ImageSampler with the given
predict_fn, input and image dataset.</p>
<p>Predict_fn will be used to predict all the
samples and the input.</p>
<p>When dataset equals None samples are generated
by utilising mean superpixels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code>any</code></dt>
<dd>Image that is to be explained.</dd>
<dt><strong><code>predict_fn</code></strong> :&ensp;<code>Callable[[any], np.array]</code></dt>
<dd>Black box model predict function.</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>any</code></dt>
<dd>Image dataset from which samples will be collected</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ImageSampler(Sampler):
    &#34;&#34;&#34;
    Image sampling with the help of superpixels.
    The original input image is permuated by switching off superpixel areas.

    More details can be found on the following website:
    https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/
    &#34;&#34;&#34;

    type: Tasktype = Tasktype.IMAGE

    def __init__(
        self, input: any, predict_fn: Callable[[any], np.array], dataset: any = None
    ):
        &#34;&#34;&#34;
        Initialises ImageSampler with the given
        predict_fn, input and image dataset.

        Predict_fn will be used to predict all the 
        samples and the input.

        When dataset equals None samples are generated
        by utilising mean superpixels.

        Args:
            input (any): Image that is to be explained.
            predict_fn (Callable[[any], np.array]): Black box model predict function.
            dataset (any): Image dataset from which samples will be collected
        &#34;&#34;&#34;

        assert input.shape[2] == 3
        assert len(input.shape) == 3

        self.label = predict_fn(input[np.newaxis, ...])

        input = input.clone().cpu().detach().numpy()
        # run segmentation on the image
        self.features = quickshift(
            input.astype(np.double), kernel_size=4, max_dist=200, ratio=0.2
        )

        # parameters from original implementation
        segment_features = np.unique(self.features)
        self._n_features = len(segment_features)

        # create superpixel image by replacing superpixels by its mean in the original image
        self.sp_image = np.copy(input)
        for spixel in segment_features:
            self.sp_image[self.features == spixel, :] = np.mean(
                self.sp_image[self.features == spixel, :], axis=0
            )

        self.image = input
        self.predict_fn = predict_fn
        self.dataset = dataset

    def sample(
        self,
        candidate: AnchorCandidate,
        num_samples: int,
        calculate_labels: bool = True,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generates num_samples samples by choosing random values
        out of self.dataset and setting the self.input features 
        that are withing the candidates feature mask.

        When dataset is None then samples are generated by 
        utilizing the mean superpixel else the image datset
        is sampled

        Args:
            candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
            num_samples (int): Number of samples that shall be generated.
            calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
            candiates precision will be updated. Defaults to True.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, segmentations]. In case 
            calculate_labels is False return [None, coverage_mask, None].
        &#34;&#34;&#34;
        data = np.random.randint(
            0, 2, size=(num_samples, self._n_features)
        )  # generate random feature mask for each sample
        data[:, candidate.feature_mask] = 1  # set present features to one

        if not calculate_labels:
            return None, data, None

        if self.dataset is not None:
            return self.sample_dataset(candidate, data, num_samples)
        else:
            return self.sample_mean_superpixel(candidate, data, num_samples)

    def sample_dataset(
        self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Samples num_samples samples by utilising the image dataset.

        Args:
            candidate (AnchorCandidate): AnchorCandiate that shall be evaluted
            data (np.ndarray): Features masks
            num_samples (int): Number of samples to be generated.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, segmentations]
        &#34;&#34;&#34;
        perturb_sample_idxs = np.random.choice(
            range(self.dataset.shape[0]), num_samples, replace=True
        )

        samples = np.stack(
            [
                self.__generate_image(mask, self.dataset[pidx])
                for mask, pidx in zip(data, perturb_sample_idxs)
            ],
            axis=0,
        )

        preds = self.predict_fn(samples)
        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)

        return candidate, data, self.features

    def sample_mean_superpixel(
        self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Sample function for image data.
        Generates random image samples from the distribution around the original image.

        Args:
            candidate (AnchorCandidate)
            num_samples (int)
        Returns:
            candidate (AnchorCandidate)
        &#34;&#34;&#34;
        samples = np.stack(
            [self.__generate_image(mask, self.sp_image) for mask in data], axis=0
        )

        preds = self.predict_fn(samples)

        # assert isinstance(
        #     preds, np.ndarray
        # ), &#34;Result of your predict function should be of type numpy.ndarray&#34;

        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)

        return candidate, data, self.features  # TODO remove third return variable

    def __generate_image(
        self, feature_mask: np.ndarray, perturb_image: np.ndarray
    ) -&gt; np.array:
        &#34;&#34;&#34;
        Generate sample image given some feature mask.
        The true image will get permutated dependent on the feature mask.
        Pixel which are outmasked by the mask are replaced by the corresponding superpixel pixel.

        Args:
            feature_mask: np.ndarray
        Returns:
            permutated image: np.array
        &#34;&#34;&#34;
        img = self.image.copy()
        zeros = np.where(feature_mask == 0)[0]
        mask = np.zeros(self.features.shape).astype(bool)
        for z in zeros:
            mask[self.features == z] = True
        img[mask] = perturb_image[mask]

        return img

    @property
    def num_features(self):
        return self._n_features</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler">Sampler</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.type"><code class="name">var <span class="ident">type</span> : iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.num_features"><code class="name">var <span class="ident">num_features</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_features(self):
    return self._n_features</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, candidate: iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, num_samples: int, calculate_labels: bool = True) ‑> Tuple[iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Generates num_samples samples by choosing random values
out of self.dataset and setting the self.input features
that are withing the candidates feature mask.</p>
<p>When dataset is None then samples are generated by
utilizing the mean superpixel else the image datset
is sampled</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>candidate</code></strong> :&ensp;<code>AnchorCandidate</code></dt>
<dd>AnchorCandiate which contains the features to be fixated.</dd>
<dt><strong><code>num_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of samples that shall be generated.</dd>
<dt><strong><code>calculate_labels</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>When true label of the samples will predicted. In that case the </dd>
</dl>
<p>candiates precision will be updated. Defaults to True.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[AnchorCandidate, np.ndarray, np.ndarray]</code></dt>
<dd>Structure: [AnchorCandiate, coverage_mask, segmentations]. In case </dd>
</dl>
<p>calculate_labels is False return [None, coverage_mask, None].</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(
    self,
    candidate: AnchorCandidate,
    num_samples: int,
    calculate_labels: bool = True,
) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Generates num_samples samples by choosing random values
    out of self.dataset and setting the self.input features 
    that are withing the candidates feature mask.

    When dataset is None then samples are generated by 
    utilizing the mean superpixel else the image datset
    is sampled

    Args:
        candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
        num_samples (int): Number of samples that shall be generated.
        calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
        candiates precision will be updated. Defaults to True.

    Returns:
        Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, segmentations]. In case 
        calculate_labels is False return [None, coverage_mask, None].
    &#34;&#34;&#34;
    data = np.random.randint(
        0, 2, size=(num_samples, self._n_features)
    )  # generate random feature mask for each sample
    data[:, candidate.feature_mask] = 1  # set present features to one

    if not calculate_labels:
        return None, data, None

    if self.dataset is not None:
        return self.sample_dataset(candidate, data, num_samples)
    else:
        return self.sample_mean_superpixel(candidate, data, num_samples)</code></pre>
</details>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample_dataset"><code class="name flex">
<span>def <span class="ident">sample_dataset</span></span>(<span>self, candidate: iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, data: numpy.ndarray, num_samples: int) ‑> Tuple[iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Samples num_samples samples by utilising the image dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>candidate</code></strong> :&ensp;<code>AnchorCandidate</code></dt>
<dd>AnchorCandiate that shall be evaluted</dd>
<dt><strong><code>data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Features masks</dd>
<dt><strong><code>num_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of samples to be generated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[AnchorCandidate, np.ndarray, np.ndarray]</code></dt>
<dd>Structure: [AnchorCandiate, coverage_mask, segmentations]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_dataset(
    self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Samples num_samples samples by utilising the image dataset.

    Args:
        candidate (AnchorCandidate): AnchorCandiate that shall be evaluted
        data (np.ndarray): Features masks
        num_samples (int): Number of samples to be generated.

    Returns:
        Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, segmentations]
    &#34;&#34;&#34;
    perturb_sample_idxs = np.random.choice(
        range(self.dataset.shape[0]), num_samples, replace=True
    )

    samples = np.stack(
        [
            self.__generate_image(mask, self.dataset[pidx])
            for mask, pidx in zip(data, perturb_sample_idxs)
        ],
        axis=0,
    )

    preds = self.predict_fn(samples)
    labels = (preds == self.label).astype(int)

    # update candidate
    candidate.update_precision(np.sum(labels), num_samples)

    return candidate, data, self.features</code></pre>
</details>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample_mean_superpixel"><code class="name flex">
<span>def <span class="ident">sample_mean_superpixel</span></span>(<span>self, candidate: iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, data: numpy.ndarray, num_samples: int) ‑> Tuple[iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Sample function for image data.
Generates random image samples from the distribution around the original image.</p>
<h2 id="args">Args</h2>
<p>candidate (AnchorCandidate)
num_samples (int)</p>
<h2 id="returns">Returns</h2>
<p>candidate (AnchorCandidate)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_mean_superpixel(
    self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Sample function for image data.
    Generates random image samples from the distribution around the original image.

    Args:
        candidate (AnchorCandidate)
        num_samples (int)
    Returns:
        candidate (AnchorCandidate)
    &#34;&#34;&#34;
    samples = np.stack(
        [self.__generate_image(mask, self.sp_image) for mask in data], axis=0
    )

    preds = self.predict_fn(samples)

    # assert isinstance(
    #     preds, np.ndarray
    # ), &#34;Result of your predict function should be of type numpy.ndarray&#34;

    labels = (preds == self.label).astype(int)

    # update candidate
    candidate.update_precision(np.sum(labels), num_samples)

    return candidate, data, self.features  # TODO remove third return variable</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler">Sampler</a></b></code>:
<ul class="hlist">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create">create</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler"><code class="flex name class">
<span>class <span class="ident">Sampler</span></span>
</code></dt>
<dd>
<div class="desc"><p>Abstract Sampler that is used as a factory for its
subclasses. Use create(Tasktype) to initialise sub-
classes for each task.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Sampler:
    &#34;&#34;&#34;
    Abstract Sampler that is used as a factory for its
    subclasses. Use create(Tasktype) to initialise sub-
    classes for each task.
    &#34;&#34;&#34;

    subclasses = {}

    def __init_subclass__(cls, **kwargs):
        &#34;&#34;&#34;
        Registers every subclass in the subclass-dict.
        &#34;&#34;&#34;
        super().__init_subclass__(**kwargs)
        cls.subclasses[cls.type] = cls

    @classmethod
    def create(
        cls,
        type: Tasktype,
        input: any,
        predict_fn: Callable,
        task_specific: dict,
        **kwargs
    ):
        &#34;&#34;&#34;
        Creates subclass depending on typ.

        Args:
            typ: Tasktype
        Returns:
            Subclass that is used for the given Tasktype.
        &#34;&#34;&#34;
        if type not in cls.subclasses:
            raise ValueError(&#34;Bad message type {}&#34;.format(type))

        return cls.subclasses[type](
            input, predict_fn, **task_specific
        )  # every sampler needs input and predict function</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler">ImageSampler</a></li>
<li><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler">TabularSampler</a></li>
<li><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler">TextSampler</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.subclasses"><code class="name">var <span class="ident">subclasses</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create"><code class="name flex">
<span>def <span class="ident">create</span></span>(<span>type: iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype, input: <built-in function any>, predict_fn: Callable, task_specific: dict, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates subclass depending on typ.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>typ</code></strong></dt>
<dd>Tasktype</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Subclass that is used for the given Tasktype.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def create(
    cls,
    type: Tasktype,
    input: any,
    predict_fn: Callable,
    task_specific: dict,
    **kwargs
):
    &#34;&#34;&#34;
    Creates subclass depending on typ.

    Args:
        typ: Tasktype
    Returns:
        Subclass that is used for the given Tasktype.
    &#34;&#34;&#34;
    if type not in cls.subclasses:
        raise ValueError(&#34;Bad message type {}&#34;.format(type))

    return cls.subclasses[type](
        input, predict_fn, **task_specific
    )  # every sampler needs input and predict function</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler"><code class="flex name class">
<span>class <span class="ident">TabularSampler</span></span>
<span>(</span><span>input: <built-in function any>, predict_fn: Callable[[<built-in function any>], <built-in function array>], dataset: <built-in function any>, column_names: list)</span>
</code></dt>
<dd>
<div class="desc"><p>TabularSampler generates new tabular instances
given an AnchorCandidate by fixiating the
candidates features and sampling random values
within the dataset.</p>
<p>Initialises TabularSampler with the given
predict_fn, input, dataset and column names.</p>
<p>Predict_fn will be used to predict all the
samples and the input.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code>any</code></dt>
<dd>Tabular row that is to be explained.</dd>
<dt><strong><code>predict_fn</code></strong> :&ensp;<code>Callable[[any], np.array]</code></dt>
<dd>Black box model predict function.</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>any</code></dt>
<dd>Tabular dataset from which samples will be collected.</dd>
<dt><strong><code>column_names</code></strong> :&ensp;<code>list</code></dt>
<dd>Columns names of the dataset.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TabularSampler(Sampler):
    &#34;&#34;&#34;
    TabularSampler generates new tabular instances 
    given an AnchorCandidate by fixiating the 
    candidates features and sampling random values
    within the dataset.
    &#34;&#34;&#34;

    type: Tasktype = Tasktype.TABULAR

    def __init__(
        self,
        input: any,
        predict_fn: Callable[[any], np.array],
        dataset: any,
        column_names: list,
    ):
        &#34;&#34;&#34;
        Initialises TabularSampler with the given
        predict_fn, input, dataset and column names.

        Predict_fn will be used to predict all the 
        samples and the input.

        Args:
            input (any): Tabular row that is to be explained.
            predict_fn (Callable[[any], np.array]): Black box model predict function.
            dataset (any): Tabular dataset from which samples will be collected.
            column_names (list): Columns names of the dataset.
        &#34;&#34;&#34;

        if dataset is None:
            assert &#34;Dataset must be given for tabular explaination.&#34;
        if column_names is None:
            assert &#34;Column names must be given for tabular explaination.&#34;

        self.predict_fn = predict_fn
        self.input = input
        self.label = predict_fn(input)
        self.dataset = dataset
        self.features = column_names
        self.num_features = self.dataset.shape[1]

        assert (
            len(column_names) == self.num_features
        ), &#34;column_names length must match dataset column dimension.&#34;

    def sample(
        self,
        candidate: AnchorCandidate,
        num_samples: int,
        calculate_labels: bool = True,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generates num_samples samples by choosing random values
        out of self.dataset and setting the self.input features 
        that are withing the candidates feature mask.

        Args:
            candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
            num_samples (int): Number of samples that shall be generated.
            calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
            candiates precision will be updated. Defaults to True.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, None]. In case 
            calculate_labels is False return [None, coverage_mask, None].
        &#34;&#34;&#34;

        if self.dataset.shape[0] &gt; num_samples:
            assert &#34;Batch size must be smaller or equal to dataset rows.&#34;

        # pertubate
        sample_idxs = np.random.choice(
            self.dataset.shape[0], size=num_samples, replace=False
        )

        # fixiate feature mask
        samples = np.copy(self.dataset[sample_idxs])
        samples[:, candidate.feature_mask] = self.input[0, candidate.feature_mask]

        # calculate converage mask
        masks = (samples[:, :] != self.input).astype(int)

        if not calculate_labels:
            return None, masks, None

        # predict samples
        preds = self.predict_fn(samples)

        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)

        return candidate, masks, None  # TODO remove third return variable</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler">Sampler</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler.type"><code class="name">var <span class="ident">type</span> : iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, candidate: iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, num_samples: int, calculate_labels: bool = True) ‑> Tuple[iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Generates num_samples samples by choosing random values
out of self.dataset and setting the self.input features
that are withing the candidates feature mask.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>candidate</code></strong> :&ensp;<code>AnchorCandidate</code></dt>
<dd>AnchorCandiate which contains the features to be fixated.</dd>
<dt><strong><code>num_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of samples that shall be generated.</dd>
<dt><strong><code>calculate_labels</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>When true label of the samples will predicted. In that case the </dd>
</dl>
<p>candiates precision will be updated. Defaults to True.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[AnchorCandidate, np.ndarray, np.ndarray]</code></dt>
<dd>Structure: [AnchorCandiate, coverage_mask, None]. In case </dd>
</dl>
<p>calculate_labels is False return [None, coverage_mask, None].</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(
    self,
    candidate: AnchorCandidate,
    num_samples: int,
    calculate_labels: bool = True,
) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Generates num_samples samples by choosing random values
    out of self.dataset and setting the self.input features 
    that are withing the candidates feature mask.

    Args:
        candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
        num_samples (int): Number of samples that shall be generated.
        calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
        candiates precision will be updated. Defaults to True.

    Returns:
        Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, None]. In case 
        calculate_labels is False return [None, coverage_mask, None].
    &#34;&#34;&#34;

    if self.dataset.shape[0] &gt; num_samples:
        assert &#34;Batch size must be smaller or equal to dataset rows.&#34;

    # pertubate
    sample_idxs = np.random.choice(
        self.dataset.shape[0], size=num_samples, replace=False
    )

    # fixiate feature mask
    samples = np.copy(self.dataset[sample_idxs])
    samples[:, candidate.feature_mask] = self.input[0, candidate.feature_mask]

    # calculate converage mask
    masks = (samples[:, :] != self.input).astype(int)

    if not calculate_labels:
        return None, masks, None

    # predict samples
    preds = self.predict_fn(samples)

    labels = (preds == self.label).astype(int)

    # update candidate
    candidate.update_precision(np.sum(labels), num_samples)

    return candidate, masks, None  # TODO remove third return variable</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler">Sampler</a></b></code>:
<ul class="hlist">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create">create</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype"><code class="flex name class">
<span>class <span class="ident">Tasktype</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Type of data that is going to be explained by the
anchor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Tasktype(Enum):
    &#34;&#34;&#34;
    Type of data that is going to be explained by the
    anchor.
    &#34;&#34;&#34;

    TABULAR = auto()
    IMAGE = auto()
    TEXT = auto()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.IMAGE"><code class="name">var <span class="ident">IMAGE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.TABULAR"><code class="name">var <span class="ident">TABULAR</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.TEXT"><code class="name">var <span class="ident">TEXT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler"><code class="flex name class">
<span>class <span class="ident">TextSampler</span></span>
<span>(</span><span>input: <built-in function any>, predict_fn: Callable[[<built-in function any>], <built-in function array>])</span>
</code></dt>
<dd>
<div class="desc"><p>TextSampler generates new text instances
given an AnchorCandidate by fixiating the
candidates features and replacing masked
words with alternatives given from bert
model.</p>
<p>Initialises TextSampler with the given
predict_fn, input, dataset and nlp_object</p>
<p>Predict_fn will be used to predict all the
samples and the input.</p>
<h2 id="args">Args</h2>
<dl>
<dt>input (list(str)): Sentences as list of tokens.</dt>
<dt><strong><code>predict_fn</code></strong> :&ensp;<code>Callable[[any], np.array]</code></dt>
<dd>Black box model predict function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TextSampler(Sampler):
    &#34;&#34;&#34;
    TextSampler generates new text instances 
    given an AnchorCandidate by fixiating the 
    candidates features and replacing masked 
    words with alternatives given from bert 
    model.
    &#34;&#34;&#34;

    type: Tasktype = Tasktype.TEXT

    def __init__(self, input: any, predict_fn: Callable[[any], np.array]):
        &#34;&#34;&#34;
        Initialises TextSampler with the given
        predict_fn, input, dataset and nlp_object

        Predict_fn will be used to predict all the 
        samples and the input.

        Args:
            input (list(str)): Sentences as list of tokens.
            predict_fn (Callable[[any], np.array]): Black box model predict function.
        &#34;&#34;&#34;
        self.label = predict_fn([&#34; &#34;.join(input)])
        self.input = input
        self.num_features = len(self.input)
        self.predict_fn = predict_fn

        self.tokenizer = DistilBertTokenizer.from_pretrained(&#34;distilbert-base-cased&#34;)
        self.bert = DistilBertForMaskedLM.from_pretrained(&#34;distilbert-base-cased&#34;)

        # contains top500k probability of each word in the input
        self.pr = {}

        # caches bert predictions
        self.prob_cache = {}

        # mask each word separetly and predict topk given its context
        for i in range(len(self.input)):
            masked_sentence = self.input.copy()
            masked_sentence[i] = self.tokenizer.mask_token

            sentence = &#34; &#34;.join(masked_sentence)

            w, p = self.prob(sentence)[0]
            self.pr[self.input[i]] = min(0.5, dict(zip(w, p)).get(self.input[i], 0.01))

    def prob(self, sentence: str):
        &#34;&#34;&#34;
        Given a senteces with masked tokens predicts
        the cbow (word alternatives, exp normalized 
        probabilites) for each word.

        Args:
            sentence (str): Sentences which maskes word alternatives
                            and probabilites shall be predicted.

        Returns:
            results (list(tuple(str, float)))
        &#34;&#34;&#34;
        if sentence in self.prob_cache:
            return self.prob_cache[sentence]

        result = self.pred_topk_cbow(sentence)
        normalized_result = [(a, exp_normalize(b)) for a, b in result]

        self.prob_cache[sentence] = normalized_result
        return normalized_result

    def pred_topk_cbow(self, sentence):
        &#34;&#34;&#34;
        Give a sentences with masked tokens predict 
        alternative words (and the corresponding probabilities)
        via bert.

        For each masked token returns the top500 predictions
        with their probabilities.

        Returns:
            predictions (list(tuple(str, float)))
        &#34;&#34;&#34;
        # encode text
        encoded_text = self.tokenizer.encode(sentence, add_special_tokens=True)
        input = torch.tensor([encoded_text])

        with torch.no_grad():
            output = self.bert(input)[0]

        # get idx for mask token
        mask_token_idx = (
            np.array(encoded_text) == self.tokenizer.mask_token_id
        ).nonzero()[0]

        # predict top 500 for each masked word
        preds_per_word = []
        for i in mask_token_idx:
            v, top_preds = torch.topk(output[0, i], 500)
            words = self.tokenizer.convert_ids_to_tokens(top_preds)
            preds_per_word.append((words, v.numpy()))

        return preds_per_word

    def sample(
        self,
        candidate: AnchorCandidate,
        num_samples: int,
        calculate_labels: bool = True,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generates num_samples samples by choosing if words 
        that are not within the candiates feature mask should
        be masked given their original probability (self.pr).

        Args:
            candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
            num_samples (int): Number of samples that shall be generated.
            calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
            candiates precision will be updated. Defaults to True.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, None]. In case 
            calculate_labels is False return [None, coverage_mask, None].
        &#34;&#34;&#34;
        feature_masks = np.zeros((num_samples, len(self.input)))
        for idx, word in enumerate(self.input):
            if idx in candidate.feature_mask:
                continue

            # decide if we should mask the word or not
            prob = self.pr[word]
            feature_masks[:, idx] = np.random.choice(
                [0, 1], num_samples, p=[1 - prob, prob]
            )

        # unmask words in candidate mask
        feature_masks[:, candidate.feature_mask] = 1

        if not calculate_labels:
            return None, feature_masks, None

        return self.__sample_pertubated_sentences(candidate, feature_masks, num_samples)

    def __generate_sentence(self, feature_mask: np.ndarray) -&gt; str:
        &#34;&#34;&#34;
        Generate new sentence by masking words according to the
        feature mask. For each masked word new words are samples.
        This is done word for word in an iterative manner to generate
        more coherent sentences.

        Args:
            feature_mask (np.ndarray): Features mask where != 1 denotes 
                                        that a word shall be masked

        Returns:
            str: Generated sentence
        &#34;&#34;&#34;
        # Generate new sentences by masking words according to the
        # feature mask. Then new words are samples. This is done
        # done word for word

        # mask words given the feature mask
        sentence_cp = np.array(self.input, dtype=&#34;|U80&#34;)
        sentence_cp[feature_mask != 1] = self.tokenizer.mask_token

        # sample new word for each word
        masked_word = np.where(feature_mask == 0)[0]
        for word_idx in masked_word:
            mod_sentence = &#34; &#34;.join(sentence_cp)
            words, probs = self.prob(mod_sentence)[0]
            sentence_cp[word_idx] = np.random.choice(words, p=probs)

        feature_mask = sentence_cp == np.array(self.input, dtype=&#34;|U80&#34;)

        return &#34; &#34;.join(sentence_cp)

    def __sample_pertubated_sentences(
        self, candidate: AnchorCandidate, data: np.ndarray, num_samples: int,
    ) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Generate num_sampels new sentences (via self.__generate_sentence),
        predicts the labels and updates the precision for the AnchorCandidate
        candidate.

        Args:
            candidate (AnchorCandidate): Candidate for which the samples will be generated for. 
                                            This candiates precisision will be updated in the process.
            data (np.ndarray): Several feature_masks. For each mask a new sentence will be generated.
            num_samples (int): Number of samples. Used to calculate the precision.

        Returns:
            Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure [AnchorCandidate, feature_masks, None]
        &#34;&#34;&#34;
        sentences = np.apply_along_axis(self.__generate_sentence, 1, data).reshape(
            -1, 1
        )

        # predict pertubed sentences
        preds = self.predict_fn(sentences.flatten().tolist())
        labels = (preds == self.label).astype(int)

        # update candidate
        candidate.update_precision(np.sum(labels), num_samples)
        return candidate, data, None</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler">Sampler</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.type"><code class="name">var <span class="ident">type</span> : iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.pred_topk_cbow"><code class="name flex">
<span>def <span class="ident">pred_topk_cbow</span></span>(<span>self, sentence)</span>
</code></dt>
<dd>
<div class="desc"><p>Give a sentences with masked tokens predict
alternative words (and the corresponding probabilities)
via bert.</p>
<p>For each masked token returns the top500 predictions
with their probabilities.</p>
<h2 id="returns">Returns</h2>
<p>predictions (list(tuple(str, float)))</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pred_topk_cbow(self, sentence):
    &#34;&#34;&#34;
    Give a sentences with masked tokens predict 
    alternative words (and the corresponding probabilities)
    via bert.

    For each masked token returns the top500 predictions
    with their probabilities.

    Returns:
        predictions (list(tuple(str, float)))
    &#34;&#34;&#34;
    # encode text
    encoded_text = self.tokenizer.encode(sentence, add_special_tokens=True)
    input = torch.tensor([encoded_text])

    with torch.no_grad():
        output = self.bert(input)[0]

    # get idx for mask token
    mask_token_idx = (
        np.array(encoded_text) == self.tokenizer.mask_token_id
    ).nonzero()[0]

    # predict top 500 for each masked word
    preds_per_word = []
    for i in mask_token_idx:
        v, top_preds = torch.topk(output[0, i], 500)
        words = self.tokenizer.convert_ids_to_tokens(top_preds)
        preds_per_word.append((words, v.numpy()))

    return preds_per_word</code></pre>
</details>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.prob"><code class="name flex">
<span>def <span class="ident">prob</span></span>(<span>self, sentence: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a senteces with masked tokens predicts
the cbow (word alternatives, exp normalized
probabilites) for each word.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sentence</code></strong> :&ensp;<code>str</code></dt>
<dd>Sentences which maskes word alternatives
and probabilites shall be predicted.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>results (list(tuple(str, float)))</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prob(self, sentence: str):
    &#34;&#34;&#34;
    Given a senteces with masked tokens predicts
    the cbow (word alternatives, exp normalized 
    probabilites) for each word.

    Args:
        sentence (str): Sentences which maskes word alternatives
                        and probabilites shall be predicted.

    Returns:
        results (list(tuple(str, float)))
    &#34;&#34;&#34;
    if sentence in self.prob_cache:
        return self.prob_cache[sentence]

    result = self.pred_topk_cbow(sentence)
    normalized_result = [(a, exp_normalize(b)) for a, b in result]

    self.prob_cache[sentence] = normalized_result
    return normalized_result</code></pre>
</details>
</dd>
<dt id="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, candidate: iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, num_samples: int, calculate_labels: bool = True) ‑> Tuple[iml-ws21-projects-risingnumpygods.Anchor.candidate.AnchorCandidate, numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Generates num_samples samples by choosing if words
that are not within the candiates feature mask should
be masked given their original probability (self.pr).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>candidate</code></strong> :&ensp;<code>AnchorCandidate</code></dt>
<dd>AnchorCandiate which contains the features to be fixated.</dd>
<dt><strong><code>num_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of samples that shall be generated.</dd>
<dt><strong><code>calculate_labels</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>When true label of the samples will predicted. In that case the </dd>
</dl>
<p>candiates precision will be updated. Defaults to True.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[AnchorCandidate, np.ndarray, np.ndarray]</code></dt>
<dd>Structure: [AnchorCandiate, coverage_mask, None]. In case </dd>
</dl>
<p>calculate_labels is False return [None, coverage_mask, None].</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(
    self,
    candidate: AnchorCandidate,
    num_samples: int,
    calculate_labels: bool = True,
) -&gt; Tuple[AnchorCandidate, np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Generates num_samples samples by choosing if words 
    that are not within the candiates feature mask should
    be masked given their original probability (self.pr).

    Args:
        candidate (AnchorCandidate): AnchorCandiate which contains the features to be fixated.
        num_samples (int): Number of samples that shall be generated.
        calculate_labels (bool, optional): When true label of the samples will predicted. In that case the 
        candiates precision will be updated. Defaults to True.

    Returns:
        Tuple[AnchorCandidate, np.ndarray, np.ndarray]: Structure: [AnchorCandiate, coverage_mask, None]. In case 
        calculate_labels is False return [None, coverage_mask, None].
    &#34;&#34;&#34;
    feature_masks = np.zeros((num_samples, len(self.input)))
    for idx, word in enumerate(self.input):
        if idx in candidate.feature_mask:
            continue

        # decide if we should mask the word or not
        prob = self.pr[word]
        feature_masks[:, idx] = np.random.choice(
            [0, 1], num_samples, p=[1 - prob, prob]
        )

    # unmask words in candidate mask
    feature_masks[:, candidate.feature_mask] = 1

    if not calculate_labels:
        return None, feature_masks, None

    return self.__sample_pertubated_sentences(candidate, feature_masks, num_samples)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler">Sampler</a></b></code>:
<ul class="hlist">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create">create</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor" href="index.html">iml-ws21-projects-risingnumpygods.Anchor</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.exp_normalize" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.exp_normalize">exp_normalize</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler">ImageSampler</a></code></h4>
<ul class="">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.num_features" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.num_features">num_features</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample">sample</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample_dataset" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample_dataset">sample_dataset</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample_mean_superpixel" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.sample_mean_superpixel">sample_mean_superpixel</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.type" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.ImageSampler.type">type</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler">Sampler</a></code></h4>
<ul class="">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.create">create</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.subclasses" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Sampler.subclasses">subclasses</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler">TabularSampler</a></code></h4>
<ul class="">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler.sample" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler.sample">sample</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler.type" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TabularSampler.type">type</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype">Tasktype</a></code></h4>
<ul class="">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.IMAGE" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.IMAGE">IMAGE</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.TABULAR" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.TABULAR">TABULAR</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.TEXT" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.Tasktype.TEXT">TEXT</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler">TextSampler</a></code></h4>
<ul class="">
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.pred_topk_cbow" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.pred_topk_cbow">pred_topk_cbow</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.prob" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.prob">prob</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.sample" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.sample">sample</a></code></li>
<li><code><a title="iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.type" href="#iml-ws21-projects-risingnumpygods.Anchor.sampler.TextSampler.type">type</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>